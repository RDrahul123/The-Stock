{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upper-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def scale_range(x, input_range, target_range):\n",
    "    \"\"\"\n",
    "\n",
    "    Rescale a numpy array from input to target range\n",
    "    :param x: data to scale\n",
    "    :param input_range: optional input range for data: default 0.0:1.0\n",
    "    :param target_range: optional target range for data: default 0.0:1.0\n",
    "    :return: rescaled array, incoming range [min,max]\n",
    "    \"\"\"\n",
    "\n",
    "    range = [np.amin(x), np.amax(x)]\n",
    "    x_std = (x - input_range[0]) / (1.0*(input_range[1] - input_range[0]))\n",
    "    x_scaled = x_std * (1.0*(target_range[1] - target_range[0])) + target_range[0]\n",
    "    return x_scaled, range\n",
    "\n",
    "\n",
    "def train_test_split_linear_regression(stocks):\n",
    "    \"\"\"\n",
    "        Split the data set into training and testing feature for Linear Regression Model\n",
    "        :param stocks: whole data set containing ['Open','Close','Volume'] features\n",
    "        :return: X_train : training sets of feature\n",
    "        :return: X_test : test sets of feature\n",
    "        :return: y_train: training sets of label\n",
    "        :return: y_test: test sets of label\n",
    "        :return: label_range: scaled range of label used in predicting price,\n",
    "    \"\"\"\n",
    "    # Create numpy arrays for features and targets\n",
    "    feature = []\n",
    "    label = []\n",
    "\n",
    "    # Convert dataframe columns to numpy arrays for scikit learn\n",
    "    for index, row in stocks.iterrows():\n",
    "        # print([np.array(row['Item'])])\n",
    "        feature.append([(row['Item'])])\n",
    "        label.append([(row['Close'])])\n",
    "\n",
    "    # Regularize the feature and target arrays and store min/max of input data for rescaling later\n",
    "    feature_bounds = [min(feature), max(feature)]\n",
    "    feature_bounds = [feature_bounds[0][0], feature_bounds[1][0]]\n",
    "    label_bounds = [min(label), max(label)]\n",
    "    label_bounds = [label_bounds[0][0], label_bounds[1][0]]\n",
    "\n",
    "    feature_scaled, feature_range = scale_range(np.array(feature), input_range=feature_bounds, target_range=[-1.0, 1.0])\n",
    "    label_scaled, label_range = scale_range(np.array(label), input_range=label_bounds, target_range=[-1.0, 1.0])\n",
    "\n",
    "    # Define Test/Train Split 80/20\n",
    "    split = .315\n",
    "    split = int(math.floor(len(stocks['Item']) * split))\n",
    "\n",
    "    # Set up training and test sets\n",
    "    X_train = feature_scaled[:-split]\n",
    "    X_test = feature_scaled[-split:]\n",
    "\n",
    "    y_train = label_scaled[:-split]\n",
    "    y_test = label_scaled[-split:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, label_range\n",
    "\n",
    "\n",
    "def train_test_split_lstm(stocks, prediction_time=1, test_data_size=450, unroll_length=50):\n",
    "    \"\"\"\n",
    "        Split the data set into training and testing feature for Long Short Term Memory Model\n",
    "        :param stocks: whole data set containing ['Open','Close','Volume'] features\n",
    "        :param prediction_time: no of days\n",
    "        :param test_data_size: size of test data to be used\n",
    "        :param unroll_length: how long a window should be used for train test split\n",
    "        :return: X_train : training sets of feature\n",
    "        :return: X_test : test sets of feature\n",
    "        :return: y_train: training sets of label\n",
    "        :return: y_test: test sets of label\n",
    "    \"\"\"\n",
    "    # training data\n",
    "    test_data_cut = test_data_size + unroll_length + 1\n",
    "\n",
    "    x_train = stocks[0:-prediction_time - test_data_cut].values\n",
    "    y_train = stocks[prediction_time:-test_data_cut]['Close'].values\n",
    "\n",
    "    # test data\n",
    "    x_test = stocks[0 - test_data_cut:-prediction_time].values\n",
    "    y_test = stocks[prediction_time - test_data_cut:]['Close'].values\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def unroll(data, sequence_length=24):\n",
    "    \"\"\"\n",
    "    use different windows for testing and training to stop from leak of information in the data\n",
    "    :param data: data set to be used for unrolling\n",
    "    :param sequence_length: window length\n",
    "    :return: data sets with different window.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    return np.asarray(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-swift",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
